
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>napari gallery &#8212; napari tutorials</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Fundamentals" href="fundamentals/README.html" />
    <link rel="prev" title="napari tutorials" href="index.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.ico" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">napari tutorials</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   napari tutorials
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   napari gallery
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="fundamentals/README.html">
   Fundamentals
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/installation.html">
     napari installation tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/getting_started.html">
     getting started with napari
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/viewer.html">
     napari viewer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/image.html">
     image layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/labels.html">
     labels layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/points.html">
     points layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/shapes.html">
     shapes layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/surface.html">
     surface layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/tracks.html">
     tracks layer tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fundamentals/vectors.html">
     vectors layer tutorial
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="applications/README.html">
   Applications
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="applications/annotate_segmentation.html">
     annotating segmentation with text and bounding boxes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications/annotate_points.html">
     annotating videos with napari
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications/dask.html">
     using dask and napari to process &amp; view large datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications/napari_imageJ.html">
     Napari + ImageJ How-to-Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications/cell_tracking.html">
     single cell tracking with napari
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/gallery.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examples">
   Examples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pathology-data">
     pathology data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lattice-light-sheet-data">
     lattice light-sheet data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neural-calcium-imaging-data">
     neural calcium imaging data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mesoscope-neural-imaging-data">
     mesoscope neural imaging data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#electron-microscopy-data">
     electron microscopy data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#allen-brain-reference-atlas">
     allen brain reference atlas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-based-transcriptomic-data">
     image-based transcriptomic data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cell-biology-data">
     cell biology data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-cell-biology-data">
     more cell biology data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#volumetric-rendering-data">
     volumetric rendering data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geospatial-data">
     geospatial data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kaggle-nuclei-segmentation-data">
     kaggle nuclei segmentation data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-data">
     machine learning data
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="napari-gallery">
<h1>napari gallery<a class="headerlink" href="#napari-gallery" title="Permalink to this headline">¶</a></h1>
<p>Welcome to the <strong>napari</strong> gallery!</p>
<p>This gallery contains examples showing real scientific data visualized and annotated with <strong>napari</strong>.
Note that some of these examples were made with napari 0.1,
before the UI upgraded in the 0.2 release,
so they layout might look a little different in your version of napari,
but all these functionalities and more are still supported.</p>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#pathology-data">pathology data</a></p></li>
<li><p><a class="reference external" href="#lattice-light-sheet-data">lattice light-sheet data</a></p></li>
<li><p><a class="reference external" href="#neural-calcium-imaging-data">neural calcium imaging data</a></p></li>
<li><p><a class="reference external" href="#mesoscope-neural-imaging-data">mesoscope neural imaging data</a></p></li>
<li><p><a class="reference external" href="#electron-microscopy-data">electron microscopy data</a></p></li>
<li><p><a class="reference external" href="#allen-brain-reference-atlas">allen brain reference atlas</a></p></li>
<li><p><a class="reference external" href="#image-based-transcriptomic-data">image-based transcriptomic data</a></p></li>
<li><p><a class="reference external" href="#cell-biology-data">cell biology data</a></p></li>
<li><p><a class="reference external" href="#more-cell-biology-data">more cell biology data</a></p></li>
<li><p><a class="reference external" href="#volumetric-rendering-data">volumetric rendering data</a></p></li>
<li><p><a class="reference external" href="#geospatial-data">geospatial data</a></p></li>
<li><p><a class="reference external" href="#kaggle-nuclei-segmentation-data">kaggle nuclei segmentation data</a></p></li>
<li><p><a class="reference external" href="#machine-learning-data">machine learning data</a></p></li>
</ul>
<div class="section" id="pathology-data">
<h3>pathology data<a class="headerlink" href="#pathology-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: pathology" src="_images/pathology1.gif" /></p>
<p>This example shows an ~100k x 200k pixel pathology slide from the <a class="reference external" href="https://camelyon17.grand-challenge.org/Data/">camelyon 16 challenge</a> for cancer detection in pathology images.
We converted the multiresolution image pyramid data into a <a class="reference external" href="https://zarr.readthedocs.io">zarr</a> file,
which we could lazily read using <a class="reference external" href="https://dask.readthedocs.io/en/latest/">dask</a>,
a python library for flexible parallel computation.</p>
<p>We visualized the slide using a <code class="docutils literal notranslate"><span class="pre">Pyramid</span></code> layer.
This layer allows us to dynamically swap in different resolution levels and image tiles depending on the zoom level
so we can easily browse this large dataset without having to load it all into memory.</p>
<p>We also extracted the coordinates of two tumors on this slide and visualized them us a <code class="docutils literal notranslate"><span class="pre">Shapes</span></code> layer.
During the gif you can see us add a new <code class="docutils literal notranslate"><span class="pre">Shapes</span></code> layer and start drawing shapes over both whole areas of tissue and individual cells.</p>
</div>
<div class="section" id="lattice-light-sheet-data">
<h3>lattice light-sheet data<a class="headerlink" href="#lattice-light-sheet-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: lattice light sheet microscopy" src="_images/LLSM1.gif" /></p>
<p>This example browses over 100GB of <a class="reference external" href="https://science.sciencemag.org/content/360/6386/eaaq1392">lattice lightsheet</a> data, representing a volumetric timeseries.
Using the sliders, we can move through both the <code class="docutils literal notranslate"><span class="pre">z</span></code> dimension and the <code class="docutils literal notranslate"><span class="pre">time</span></code> dimension.
The data is stored on disk as a <a class="reference external" href="https://zarr.readthedocs.io">zarr</a> file,
which are lazily reading using <a class="reference external" href="https://dask.readthedocs.io/en/latest/">dask</a>.</p>
<p>Or rendered in 3D as a volumetric timeseries.</p>
<p><img alt="image: 3D lattice light sheet microscopy" src="_images/LLSM_3D.gif" /></p>
<p>Note that the volume has been downsampled in each spatial axis by a factor of four before displaying it.</p>
</div>
<div class="section" id="neural-calcium-imaging-data">
<h3>neural calcium imaging data<a class="headerlink" href="#neural-calcium-imaging-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: calcium imaging" src="_images/calcium_imaging.gif" /></p>
<p>This example shows calcium imaging of neurons to record neural activity
and is one of the example datasets in the <a class="reference external" href="http://neurofinder.codeneuro.org/">neurofinder</a> image segmentation challenge.
The bottom <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer contains timeseries of the neural activity.
The top <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer contains the segmented neuron regions.
The middle two <code class="docutils literal notranslate"><span class="pre">Image</span></code> layers contain helpful processed maps,
the mean and the local correlation of the timeseries.</p>
<p>In this example we use the paintbrush and fill bucket tools in the <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer
to separate two regions that were incorrectly merged and two add two regions that were missed.</p>
</div>
<div class="section" id="mesoscope-neural-imaging-data">
<h3>mesoscope neural imaging data<a class="headerlink" href="#mesoscope-neural-imaging-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: mesoscope" src="_images/mesoscope.gif" /></p>
<p>This example shows neural activity recorded with the <a class="reference external" href="https://elifesciences.org/articles/14472">2-photon random access mesoscope</a>.
The bottom <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer contains the underlying timeseries of neural activity.
The subsequent <code class="docutils literal notranslate"><span class="pre">Image</span></code> layers contain processed maps,
such as the mean, local correlation or colored correlations with other timeseries data.</p>
</div>
<div class="section" id="electron-microscopy-data">
<h3>electron microscopy data<a class="headerlink" href="#electron-microscopy-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: CREMI electron microscopy" src="_images/CREMI.gif" /></p>
<p>This example shows 3D electron microscopy data from the <a class="reference external" href="https://cremi.org/">CREMI</a> circuit reconstruction challenge.
The bottom <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer contains the underlying electron microscopy image.
The <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer immediately above it contains the segmentation mask,
where each colored region corresponds to one neuron.
Pre- and post-synaptic sites are marked with <code class="docutils literal notranslate"><span class="pre">Points</span></code> layers.</p>
</div>
<div class="section" id="allen-brain-reference-atlas">
<h3>allen brain reference atlas<a class="headerlink" href="#allen-brain-reference-atlas" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Allen brain reference atlas" src="_images/allen_brain.gif" /></p>
<p>This example shows the <a class="reference external" href="https://mouse.brain-map.org/static/atlas">allen brain reference atlas</a>,
a 3D map of the mouse brain, including its division into different brain areas.
The bottom <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer contains the underlying grayscale representation of the reference brain,
and the top <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer contains the divisions into different brain regions,
where each colored region corresponds to a different part of the brain.</p>
</div>
<div class="section" id="image-based-transcriptomic-data">
<h3>image-based transcriptomic data<a class="headerlink" href="#image-based-transcriptomic-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: smFISH transcriptomic data" src="_images/smFISH1.gif" /></p>
<p>This example shows some image-based transcriptomics data analyzed with the <a class="reference external" href="https://spacetx-starfish.readthedocs.io/en/latest/">starfish tool</a>.
Each spot in the image corresponds to an mRNA molecule.
The bottom <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer is the raw image data.
The middle <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer is the raw data after a learnt deconvolution,
and the top <code class="docutils literal notranslate"><span class="pre">Points</span></code> layer corresponds to the detected mRNA spots.</p>
<p>We can also visualize the raw and deconvolved layers as 3D volumes using the <code class="docutils literal notranslate"><span class="pre">Volume</span></code> layer.</p>
<p><img alt="image: 3D smFISH transcriptomic data" src="_images/smFISH_3D.gif" /></p>
<p>Here the raw volume is shown in a <code class="docutils literal notranslate"><span class="pre">red</span></code> colormap,
and the deconvolved volume is shown in a <code class="docutils literal notranslate"><span class="pre">green</span></code> colormap.</p>
<p>Data courtesy of Tim Wang, Svoboda Lab.</p>
</div>
<div class="section" id="cell-biology-data">
<h3>cell biology data<a class="headerlink" href="#cell-biology-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Allen cell data" src="_images/allen_cell.gif" /></p>
<p>This example shows images of cells under brightfield and fluorescent imaging.
There are four color channels of flourescently label data all blended together,
showing the cell nuclei and the distribution of targets of interest.
The top <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer shows some hand drawn regions around the nuclei,
which can be seen in blue.</p>
<p>We can also visualize the flourescent data as <code class="docutils literal notranslate"><span class="pre">Volume</span></code> layers too.</p>
<p><img alt="image: Allen cell 3D data" src="_images/allen_cell_3D.gif" /></p>
<p>Data from Allen Cell.</p>
</div>
<div class="section" id="more-cell-biology-data">
<h3>more cell biology data<a class="headerlink" href="#more-cell-biology-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Fluorescent cells (nuclei, membranes, and cytoplasm)" src="_images/cells.gif" /></p>
<p>This example shows 3 color channels of data of cell nuclei, membranes, and cytoplasm
represented using three different <code class="docutils literal notranslate"><span class="pre">Image</span></code> layers with different colormaps, blended together.
The top <code class="docutils literal notranslate"><span class="pre">Points</span></code> layer contains markers over the centers of the cell nuclei.
The second from the top <code class="docutils literal notranslate"><span class="pre">Shapes</span></code> layer,
contains polygon representations of the boundaries of the cells.
Data from ImageJ examples.</p>
<p>During the example we edit the position of some of the points and shapes,
including deleting existing ones and adding new ones.</p>
</div>
<div class="section" id="volumetric-rendering-data">
<h3>volumetric rendering data<a class="headerlink" href="#volumetric-rendering-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: 3D rendering of a stent" src="_images/stent.gif" /></p>
<p>This example shows 3D rendering of a stent
and includes the changing of colormaps and color limits.
Data from vispy examples.</p>
</div>
<div class="section" id="geospatial-data">
<h3>geospatial data<a class="headerlink" href="#geospatial-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Geospatial data from the landsat survey" src="_images/geospatial.gif" /></p>
<p>This example shows data from the <a class="reference external" href="https://landsat.gsfc.nasa.gov/landsat-8/mission-details/">landsat-8</a> survey.</p>
</div>
<div class="section" id="kaggle-nuclei-segmentation-data">
<h3>kaggle nuclei segmentation data<a class="headerlink" href="#kaggle-nuclei-segmentation-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Kaggle nuclei segmentation data" src="_images/DSB2018_browse.gif" /></p>
<p>This example browses data from the <a class="reference external" href="https://www.kaggle.com/c/data-science-bowl-2018">2018 kaggle data science bowl</a> on nuclei segmentation.
The raw images are visualized using an <code class="docutils literal notranslate"><span class="pre">Image</span></code> layer
and the segmentations are visualized using a <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer.</p>
<p>We are using <a class="reference external" href="https://dask-image.readthedocs.io">dask-image</a> to look at directories of the images
and labels and lazily them when requested by the slider.
This method can support easy browsing of training datasets with many examples
as we never need to load all the images into memory.
Note that not all images need to be the same size either.</p>
<p>We can also edit or create our own segmentations using the paintbrush and fill bucket tool in the <code class="docutils literal notranslate"><span class="pre">Labels</span></code> layer.</p>
<p><img alt="image: Editing the Kaggle nuclei segmentation data" src="_images/DSB2018_edit.gif" /></p>
</div>
<div class="section" id="machine-learning-data">
<h3>machine learning data<a class="headerlink" href="#machine-learning-data" title="Permalink to this headline">¶</a></h3>
<p><img alt="image: Ants vs Bees machine learning classification" src="_images/ants_bees.gif" /></p>
<p>This example shows data from a <a class="reference external" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">hymenoptera classification task</a>
where the goal is to separate the images of the ants and bees.
Here we are using <a class="reference external" href="https://dask-image.readthedocs.io">dask-image</a> to look at two directories of images
and lazily load each image when requested by the slider.
This method can support easy browsing of training datasets with many images
as we never need to load all the images into memory.
Note that not all images need to be the same size either.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">napari tutorials</a>
    <a class='right-next' id="next-link" href="fundamentals/README.html" title="next page">Fundamentals</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>