{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f9519b",
   "metadata": {},
   "source": [
    "# image layer tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f3350",
   "metadata": {},
   "source": [
    "Welcome to the tutorial on the **napari** `Image` layer!\n",
    "\n",
    "This tutorial assumes you have already installed **napari**, know how to launch\n",
    "the viewer, and are familiar with its layout. For help with installation see our\n",
    "[installation](./installation) tutorial. For help getting started with the\n",
    "viewer see our [getting started](./getting_started) tutorial. For help\n",
    "understanding the organisation of the viewer, including things like the layers\n",
    "list, the layer properties widgets, the layer control panels, and the dimension\n",
    "sliders see our [napari viewer](./viewer) tutorial.\n",
    "\n",
    "This tutorial will teach you about the **napari** `Image` layer, including the\n",
    "types of images that can be displayed, and how to set properties like the\n",
    "contrast, opacity, colormaps and blending mode. At the end of the tutorial you\n",
    "should understand how to add and manipulate a variety of different types of\n",
    "images both from the GUI and from the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e9688",
   "metadata": {},
   "source": [
    "## a simple example\n",
    "\n",
    "You can create a new viewer and add an image in one go using the\n",
    "`napari.view_image` method, or if you already have an existing viewer, you can\n",
    "add an image to it using `viewer.add_image`. The api of both methods is the\n",
    "same. In these examples we'll mainly use `view_image`.\n",
    "\n",
    "A simple example of viewing an image is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from skimage import data\n",
    "\n",
    "cells = data.cells3d()[30, 1]  # grab some data\n",
    "viewer = napari.view_image(cells, colormap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418fe81",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545108dd",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65346a",
   "metadata": {},
   "source": [
    "## arguments of view_image and add_image\n",
    "\n",
    "{meth}`~napari.view_layers.view_image` and {meth}`~napari.Viewer.add_image`\n",
    "accept the same layer-creation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7520e03",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "help(napari.view_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d87a0",
   "metadata": {},
   "source": [
    "## image data and numpy-like arrays\n",
    "\n",
    "napari can take any numpy-like array as input for its image layer. A numpy-like\n",
    "array can just be a [numpy\n",
    "array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html), a\n",
    "[dask array](https://docs.dask.org/en/stable/array.html), an\n",
    "[xarray](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html), a\n",
    "[zarr array](https://zarr.readthedocs.io/en/stable/api/core.html), or any other\n",
    "object that you can index into and when you call\n",
    "[`np.asarray`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.asarray.html)\n",
    "on it you get back a numpy array.\n",
    "\n",
    "The great thing about napari support array-like objects is that you get to keep\n",
    "on using your favorite array libraries without worrying about any conversions as\n",
    "we'll handle all of that for you.\n",
    "\n",
    "napari will also wait until just before it displays data onto the screen to\n",
    "actually generate a numpy array from your data, and so if you're using a library\n",
    "like `dask` or `zarr` that supports lazy loading and lazy evaluation, we won't\n",
    "force you load or compute on data that you're not looking at. This enables\n",
    "napari to seamlessly browse enormous datasets that are loaded in the right way.\n",
    "For example, here we are browsing over 100GB of lattice lightsheet data stored\n",
    "in a zarr file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd6a5f",
   "metadata": {},
   "source": [
    "![image: lattice light sheet microscopy](../assets/tutorials/LLSM.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1bfd2",
   "metadata": {},
   "source": [
    "## image pyramids\n",
    "\n",
    "For exceptionally large datasets napari supports image pyramids. An image\n",
    "pyramid is a list of arrays, where each array is downsampling of the previous\n",
    "array in the list, so that you end up with images of successively smaller and\n",
    "smaller shapes. A standard image pyramid might have a 2x downsampling at each\n",
    "level, but napari can support any type of pyramid as long as the shapes are\n",
    "getting smaller each time.\n",
    "\n",
    "Image pyramids are especially useful for incredibly large 2D images when viewed\n",
    "in 2D or incredibly large 3D images when viewed in 3D. For example this ~100k x\n",
    "200k pixel pathology image consists of 10 pyramid levels and can be easily\n",
    "browsed as at each moment in time we only load the level of the pyramid and the\n",
    "part of the image that needs to be displayed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece24041",
   "metadata": {},
   "source": [
    "![image: pathology](../assets/tutorials/pathology.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42690e18",
   "metadata": {},
   "source": [
    "This example had precomputed image pyramids stored in a zarr file, which is best\n",
    "for performance. If, however you don't have a precomputed pyramid but try and\n",
    "show a exceptionally large image napari will try and compute pyramids for you\n",
    "unless you tell it not too.\n",
    "\n",
    "You can use the `multiscale` keyword argument to specify if your data is an\n",
    "image pyramid or not. If you don't provide this value, then will try and guess\n",
    "whether your data is or needs to be an image pyramid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942228a",
   "metadata": {},
   "source": [
    "## 3D rendering of images\n",
    "\n",
    "All our layers can be rendered in both 2D and 3D mode, and one of our viewer\n",
    "buttons can toggle between each mode. The number of dimensions sliders will be 2\n",
    "or 3 less than the total number of dimensions of the layer, allowing you to\n",
    "browse volumetric timeseries data and other high dimensional data. See for\n",
    "example these cells undergoing mitosis in this volumetric timeseries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d405696",
   "metadata": {},
   "source": [
    "![image: mitorsis](../assets/tutorials/mitosis.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f045a6",
   "metadata": {},
   "source": [
    "## loading multichannel images\n",
    "Each channel in a multichannel image can be displayed as an individual layer \n",
    "by using the `channel_axis` argument in `viewer.add_image()`. All the rest\n",
    "of the arguments to `viewer.add_image()` (e.g. name, colormap, contrast_limit)\n",
    "can take the form of a list of the same size as the number of channels.\n",
    "\n",
    "For example, the multichannel image below has dimensions (60, 2, 256, 256)\n",
    "with axes ordered ZCYX (so the channel axis has an index of 1). It is loaded into \n",
    "napari in one line.\n",
    "\n",
    "```{code cell} python\n",
    "import napari\n",
    "from skimage import data\n",
    "\n",
    "cells = data.cells3d() #ZCYX image data\n",
    "\n",
    "# load multichannel image in one line\n",
    "viewer = napari.view_image(cells, channel_axis=1)\n",
    "\n",
    "# load multichannel image in one line, with additional options\n",
    "viewer = napari.view_image(\n",
    "        cells,\n",
    "        channel_axis=1,\n",
    "        name=[\"membrane\", \"nuclei\"],\n",
    "        colormap=[\"green\", \"magenta\"],\n",
    "        contrast_limits=[[1000, 20000], [1000, 50000]],\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a9b27",
   "metadata": {},
   "source": [
    "![image: multichannel image](../assets/tutorials/multichannel_cells.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66df104",
   "metadata": {},
   "source": [
    "## viewing rgb vs luminance (grayscale) images\n",
    "\n",
    "In this example we explicitly set the `rgb` keyword to be `True`\n",
    "because we know we are working with an `rgb` image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data.astronaut(), rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e8bc8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8c7bf",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e72fd5",
   "metadata": {},
   "source": [
    "If we had left that keyword argument out napari would have successfully guessed\n",
    "that we were trying to show an `rgb` or `rgba` image because the final dimension\n",
    "was 3 or 4. If you have a luminance image where the last dimension is 3 or 4 you\n",
    "can set the `rgb` property to `False` so napari handles the image correctly.\n",
    "\n",
    "`rgb` data must either be `uint8`, corresponding to values between 0 and 255, or\n",
    "`float` and between 0 and 1. If the values are `float` and outside the 0 to 1\n",
    "range they will be clipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36295ffa",
   "metadata": {},
   "source": [
    "## working with colormaps\n",
    "\n",
    "napari supports any colormap that is created with `vispy.color.Colormap`. We\n",
    "provide access to some standard colormaps that you can set using a string of\n",
    "their name. These include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(napari.utils.colormaps.AVAILABLE_COLORMAPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff44a2",
   "metadata": {},
   "source": [
    "Passing any of these strings as follows to set the image colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a41a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data.moon(), colormap='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280685d",
   "metadata": {},
   "source": [
    "You can also access the current\n",
    "colormap through the `layer.colormap` property which returns a tuple of the\n",
    "colormap name followed by the vispy colormap object. You can list all the\n",
    "available colormaps using `layer.colormaps`.\n",
    "\n",
    "It is also possible to create your own colormaps using vispy's\n",
    "`vispy.color.Colormap` object, see it's full [documentation\n",
    "here](https://vispy.org/api/vispy.color.colormap.html#vispy.color.colormap.Colormap). Briefly, you can pass\n",
    "`Colormap` a list of length 3 or length 4 lists, corresponding to the `rgb` or\n",
    "`rgba` values at different points along the colormap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dffaf3",
   "metadata": {},
   "source": [
    "For example, to make a diverging colormap that goes from red to blue through\n",
    "black, and color a random array you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from vispy.color import Colormap\n",
    "\n",
    "cmap = Colormap([[1, 0, 0], [0, 0, 0], [0, 0, 1]])\n",
    "image = np.random.random((100, 100))\n",
    "\n",
    "viewer = napari.view_image(image, colormap=('diverging', cmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e259ca1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c5eaa",
   "metadata": {},
   "source": [
    "Note in this example how we passed the colormap keyword argument as a tuple\n",
    "containing both a name for our new custom colormap and the colormap itself. If\n",
    "we had only passed the colormap it would have been given a default name.\n",
    "\n",
    "The named colormap now appears in the dropdown menu alongside a little thumbnail\n",
    "of the full range of the colormap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63aadee",
   "metadata": {},
   "source": [
    "## adjusting contrast limits\n",
    "\n",
    "Each image layer gets mapped through its colormap according to values called\n",
    "contrast limits. The contrast limits are a 2-tuple where the second value is\n",
    "larger than the first. The smaller contrast limit corresponds to the value of\n",
    "the image data that will get mapped to the color defined by 0 in the colormap.\n",
    "All values of image data smaller than this value will also get mapped to this\n",
    "color. The larger contrast limit corresponds to the value of the image data that\n",
    "will get mapped to the color defined by 1 in the colormap. All values of image\n",
    "data larger than this value will also get mapped to this color.\n",
    "\n",
    "For example, you are looking at an image that has values between 0 and 100 with\n",
    "a standard `gray` colormap, and you set the contrast limits to `(20, 75)`. Then\n",
    "all the pixels with values less than 20 will get mapped to black, the color\n",
    "corresponding to 0 in the colormap, and all pixels with values greater than 75\n",
    "will get mapped to white, the color corresponding to 1 in the colormap. All\n",
    "other pixel values between 20 and 75 will get linearly mapped onto the range of\n",
    "colors between black and white.\n",
    "\n",
    "In napari you can set the contrast limits when creating an `Image` layer or on\n",
    "an existing layer using the `contrast_limits` keyword argument or property,\n",
    "respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2074d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data.moon(), name='moon')\n",
    "viewer.layers['moon'].contrast_limits=(100, 175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023bc99",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils import nbscreenshot\n",
    "\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ed4f7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e69d4",
   "metadata": {},
   "source": [
    "Because the contrast limits are defined by two values the corresponding slider\n",
    "has two handles, one the adjusts the smaller value, one that adjusts the larger\n",
    "value.\n",
    "\n",
    "As of right now adjusting the contrast limits has no effect for `rgb` data.\n",
    "\n",
    "If no contrast limits are passed, then napari will compute them. If your data is\n",
    "small, then napari will just take the minimum and maximum values across your\n",
    "entire image. If your data is exceptionally large, this operation can be very\n",
    "time consuming and so if you have passed an image pyramid then napari will just\n",
    "use the top level of that pyramid, or it will use the minimum and maximum values\n",
    "across the top, middle, and bottom slices of your image. In general, if working\n",
    "with big images it is recommended you explicitly set the contrast limits if you\n",
    "can.\n",
    "\n",
    "Currently if you pass contrast limits as a keyword argument to a layer then full\n",
    "extent of the contrast limits range slider will be set to those values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35878a8",
   "metadata": {},
   "source": [
    "## layer visibility\n",
    "\n",
    "All our layers support a visibility toggle that allows you to set the `visible`\n",
    "property of each layer. This property is located inside the layer widget in the\n",
    "layers list and is represented by an eye icon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec83bde",
   "metadata": {},
   "source": [
    "## layer opacity\n",
    "\n",
    "All our layers support an opacity slider and `opacity` property that allow you\n",
    "to adjust the layer opacity between 0, fully invisible and 1, fully visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c8807",
   "metadata": {},
   "source": [
    "## blending layers\n",
    "\n",
    "All our layers support three blending modes `translucent`, `additive`, and\n",
    "`opaque` that determine how the visuals for this layer get mixed with the\n",
    "visuals from the other layers.\n",
    "\n",
    "An `opaque` layer renders all the other layers below it invisible and will fade\n",
    "to black as you decrease its opacity.\n",
    "\n",
    "The `translucent` setting will cause the layer to blend with the layers below it\n",
    "if you decrease its opacity but will fully block those layers if its opacity is\n",
    "1\\. This is a reasonable default, useful for many applications.\n",
    "\n",
    "The final blending mode `additive` will cause the layer to blend with the layers\n",
    "below even when it has full opacity. This mode is especially useful for many\n",
    "cell biology applications where you have multiple different components of a cell\n",
    "labeled in different colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1299db",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "![image: blending](../assets/tutorials/blending.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36c501",
   "metadata": {},
   "source": [
    "## layer interpolation\n",
    "\n",
    "We support a variety of interpolation modes when viewing 2D slices. In the\n",
    "default mode `nearest` each pixel is represented as a small square of specified\n",
    "size. As you zoom in you will eventually see each pixel. In other modes\n",
    "neighbouring pixels are blended together according to different functions, for\n",
    "example `bicubic`, which can lead to smoother looking images. For most\n",
    "scientific use-cases `nearest` is recommended because it does not introduce more\n",
    "artificial blurring. These modes have no effect when viewing 3D slices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61884381",
   "metadata": {},
   "source": [
    "## layer rendering\n",
    "\n",
    "When viewing 3D slices, we support a variety of rendering modes. The default\n",
    "mode `mip`, or maximum intensity projection, will combine voxels at different\n",
    "distances from the camera according to a maximum intensity projection to create\n",
    "the 2D image that is then displayed on the screen. This mode works well for many\n",
    "biological images such as these cells growing in culture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aece7d",
   "metadata": {},
   "source": [
    "![image: rendering](../assets/tutorials/rendering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ff2d3",
   "metadata": {},
   "source": [
    "When viewing 2D slices the rendering mode has no effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2c92d",
   "metadata": {},
   "source": [
    "## naming layers\n",
    "\n",
    "All our layers support a `name` property that can be set inside a text box\n",
    "inside the layer widget in the layers list. The name of each layer is forced\n",
    "into being unique so that you can use the name to index into `viewer.layers` to\n",
    "retrieve the layer object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ec620",
   "metadata": {},
   "source": [
    "## scaling layers\n",
    "\n",
    "All our layers support a `scale` property and keyword argument that will rescale\n",
    "the layer multiplicatively according to the scale values (one for each\n",
    "dimension). This property can be particularly useful for viewing anisotropic\n",
    "volumes where the size of the voxel in the z dimension might be different then\n",
    "the size in the x and y dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8c682",
   "metadata": {},
   "source": [
    "## translating layers\n",
    "\n",
    "All our layers support a `translate` property and keyword argument that you can\n",
    "use to offset a layer relative to the other layers, which could be useful if you\n",
    "are trying to overlay two layers for image registration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58833b4a",
   "metadata": {},
   "source": [
    "## layer metadata\n",
    "\n",
    "All our layers also support a `metadata` property and keyword argument that you\n",
    "can use to store an arbitrary metadata dictionary on the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b8b72",
   "metadata": {},
   "source": [
    "## next steps\n",
    "\n",
    "Hopefully, this tutorial has given you a detailed understanding of the `Image`\n",
    "layer, including how to create one and control its properties. To learn more\n",
    "about some of the other layer types that **napari** supports checkout some more\n",
    "of our tutorials listed below. The [labels layer](./labels) tutorial is a great\n",
    "one to try next as labels layers are an extension of our image layers used for\n",
    "labeling regions of images."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   34,
   45,
   53,
   61,
   65,
   72,
   76,
   102,
   106,
   123,
   127,
   138,
   148,
   152,
   183,
   187,
   194,
   198,
   206,
   210,
   221,
   229,
   231,
   235,
   237,
   250,
   255,
   266,
   272,
   281,
   306,
   311,
   319,
   323,
   343,
   351,
   358,
   378,
   384,
   396,
   406,
   410,
   414,
   423,
   433,
   441,
   448
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}